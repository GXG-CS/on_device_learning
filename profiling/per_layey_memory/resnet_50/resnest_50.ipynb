{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input, Peak Memory Usage: 0.57 MB\n",
      "Layer: zeroPad, Peak Memory Usage: 0.61 MB\n",
      "Layer: conv2D, Peak Memory Usage: 3.10 MB\n",
      "Layer: maxpool, Peak Memory Usage: 0.74 MB\n",
      "Layer: stage_1_A, Peak Memory Usage: 3.52 MB\n",
      "Layer: stage_2_B, Peak Memory Usage: 6.03 MB\n",
      "Layer: stage_3_C, Peak Memory Usage: 18.77 MB\n",
      "Layer: stage_4_D, Peak Memory Usage: 72.39 MB\n",
      "Layer: avgpool, Peak Memory Usage: 0.01 MB\n",
      "Layer: fc, Peak Memory Usage: 7.82 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the dimensions of each layer in ResNet50\n",
    "layers = {\n",
    "    'input': (224, 224, 3),        # Input layer\n",
    "    'zeroPad': (230, 230, 3),      # Zero Padding\n",
    "    'conv2D': (112, 112, 64),      # Initial Conv2D\n",
    "    'maxpool': (55, 55, 64),       # Max Pooling\n",
    "    'stage_1_A': (55, 55, 256),    # Stage A - Block 1\n",
    "    'stage_2_B': (28, 28, 512),    # Stage B - Block 2\n",
    "    'stage_3_C': (14, 14, 1024),   # Stage C - Block 3\n",
    "    'stage_4_D': (7, 7, 2048),     # Stage D - Block 4\n",
    "    'avgpool': (1, 1, 2048),       # Average Pooling\n",
    "    'fc': (1, 1, 1000)             # Fully Connected Layer\n",
    "}\n",
    "\n",
    "# Define the kernel size and number of parameters for convolutional layers\n",
    "conv_kernels = {\n",
    "    'conv2D': (7, 7, 3, 64),               # Conv2D: (kernel height, kernel width, in_channels, out_channels)\n",
    "    'stage_1_A': (3, 3, 64, 256),          # Stage A: (3x3 Conv, 64->256)\n",
    "    'stage_2_B': (3, 3, 256, 512),         # Stage B: (3x3 Conv, 256->512)\n",
    "    'stage_3_C': (3, 3, 512, 1024),        # Stage C: (3x3 Conv, 512->1024)\n",
    "    'stage_4_D': (3, 3, 1024, 2048)        # Stage D: (3x3 Conv, 1024->2048)\n",
    "}\n",
    "\n",
    "# Function to compute memory in bytes for a given tensor shape\n",
    "def compute_memory(tensor_shape, dtype=np.float32):\n",
    "    element_size = np.dtype(dtype).itemsize  # Size of each element in bytes (default: float32 = 4 bytes)\n",
    "    return np.prod(tensor_shape) * element_size  # Total memory in bytes\n",
    "\n",
    "# Calculate the peak memory usage for each layer in bytes\n",
    "def peak_memory_profiling(layers, conv_kernels):\n",
    "    memory_profile = {}\n",
    "    \n",
    "    for layer_name, shape in layers.items():\n",
    "        if layer_name in conv_kernels:  # Convolutional Layer\n",
    "            # Get kernel parameters: (kernel height, kernel width, in_channels, out_channels)\n",
    "            k_h, k_w, in_ch, out_ch = conv_kernels[layer_name]\n",
    "\n",
    "            # Calculate memory for activations\n",
    "            activation_memory = compute_memory(shape)\n",
    "\n",
    "            # Calculate memory for weights (height * width * in_channels * out_channels)\n",
    "            weights_memory = compute_memory((k_h, k_w, in_ch, out_ch))\n",
    "            \n",
    "            # Calculate memory for biases (optional, usually 1 per output channel)\n",
    "            bias_memory = compute_memory((out_ch,))\n",
    "\n",
    "            # Total memory\n",
    "            peak_memory = activation_memory + weights_memory + bias_memory\n",
    "\n",
    "        elif layer_name == 'fc':  # Fully Connected Layer\n",
    "            # Fully Connected: Consider weights and output size\n",
    "            input_features = np.prod(layers['avgpool'])  # Input size to FC from the previous avgpool layer\n",
    "            output_features = shape[2]  # Number of neurons in the FC layer\n",
    "            weights_memory = compute_memory((input_features, output_features))  # Weights\n",
    "            bias_memory = compute_memory((output_features,))  # Bias memory\n",
    "            activation_memory = compute_memory(shape)\n",
    "            \n",
    "            peak_memory = activation_memory + weights_memory + bias_memory\n",
    "\n",
    "        else:  # For non-convolutional layers (like pooling)\n",
    "            peak_memory = compute_memory(shape)\n",
    "        \n",
    "        memory_profile[layer_name] = peak_memory\n",
    "    \n",
    "    return memory_profile\n",
    "\n",
    "# Run the profiling function\n",
    "memory_usage = peak_memory_profiling(layers, conv_kernels)\n",
    "\n",
    "# Convert to human-readable format and print results\n",
    "for layer, memory in memory_usage.items():\n",
    "    print(f\"Layer: {layer}, Peak Memory Usage: {memory / (1024 ** 2):.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
