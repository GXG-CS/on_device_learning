{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,020</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ layer_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m2,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m1,020\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,070</span> (11.99 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,070\u001b[0m (11.99 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,070</span> (11.99 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,070\u001b[0m (11.99 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\gxg_c\\AppData\\Local\\Temp\\tmpt3wu2apm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\gxg_c\\AppData\\Local\\Temp\\tmpt3wu2apm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\gxg_c\\AppData\\Local\\Temp\\tmpt3wu2apm'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 40), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 20), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2575034845840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2575034846016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2575035000080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2575034999904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Full model saved as 'full_large_model.tflite'.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\gxg_c\\AppData\\Local\\Temp\\tmp4izae_i5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\gxg_c\\AppData\\Local\\Temp\\tmp4izae_i5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\gxg_c\\AppData\\Local\\Temp\\tmp4izae_i5'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 40), dtype=tf.float32, name='keras_tensor_3')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 50), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2575052829968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2575052831376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Layer 1 model saved as 'layer_1.tflite'.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\gxg_c\\AppData\\Local\\Temp\\tmpka799dck\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\gxg_c\\AppData\\Local\\Temp\\tmpka799dck\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\gxg_c\\AppData\\Local\\Temp\\tmpka799dck'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50), dtype=tf.float32, name='keras_tensor_5')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 20), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2575076246976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2575076245568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Layer 2 model saved as 'layer_2.tflite'.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Create the Full Model\n",
    "# This model will contain two layers, which will be split later\n",
    "def create_full_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(40,)),  # Input layer with 40 units\n",
    "        tf.keras.layers.Dense(50, activation='relu', name='layer_1'),  # First dense layer (Server)\n",
    "        tf.keras.layers.Dense(20, activation='softmax', name='layer_2')  # Second dense layer (Client)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Step 2: Create the Layer 1 Model (Server)\n",
    "# This model only contains the first layer, producing an output of 50 units\n",
    "def create_layer_1_model():\n",
    "    layer_1_input = tf.keras.Input(shape=(40,))\n",
    "    layer_1_output = tf.keras.layers.Dense(50, activation='relu', name='layer_1')(layer_1_input)\n",
    "    return tf.keras.Model(inputs=layer_1_input, outputs=layer_1_output)\n",
    "\n",
    "# Step 3: Create the Layer 2 Model (Client)\n",
    "# This model only accepts the output of the first layer and produces the final inference\n",
    "def create_layer_2_model():\n",
    "    layer_2_input = tf.keras.Input(shape=(50,))\n",
    "    layer_2_output = tf.keras.layers.Dense(20, activation='softmax', name='layer_2')(layer_2_input)\n",
    "    return tf.keras.Model(inputs=layer_2_input, outputs=layer_2_output)\n",
    "\n",
    "# Step 4: Save the Full Model for Verification\n",
    "full_model = create_full_model()\n",
    "full_model.summary()\n",
    "\n",
    "# Step 5: Convert and Save the Full Model for Reference\n",
    "full_converter = tf.lite.TFLiteConverter.from_keras_model(full_model)\n",
    "full_tflite_model = full_converter.convert()\n",
    "with open(\"full_large_model.tflite\", \"wb\") as f:\n",
    "    f.write(full_tflite_model)\n",
    "print(\"Full model saved as 'full_large_model.tflite'.\")\n",
    "\n",
    "# Step 6: Create, Convert, and Save Layer 1 Model (Server)\n",
    "layer_1_model = create_layer_1_model()\n",
    "layer_1_converter = tf.lite.TFLiteConverter.from_keras_model(layer_1_model)\n",
    "layer_1_tflite_model = layer_1_converter.convert()\n",
    "with open(\"layer_1.tflite\", \"wb\") as f:\n",
    "    f.write(layer_1_tflite_model)\n",
    "print(\"Layer 1 model saved as 'layer_1.tflite'.\")\n",
    "\n",
    "# Step 7: Create, Convert, and Save Layer 2 Model (Client)\n",
    "layer_2_model = create_layer_2_model()\n",
    "layer_2_converter = tf.lite.TFLiteConverter.from_keras_model(layer_2_model)\n",
    "layer_2_tflite_model = layer_2_converter.convert()\n",
    "with open(\"layer_2.tflite\", \"wb\") as f:\n",
    "    f.write(layer_2_tflite_model)\n",
    "print(\"Layer 2 model saved as 'layer_2.tflite'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Input to Layer 1:\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      "Output of Layer 1 (Intermediate Output):\n",
      "[[0.5917076  0.         0.40699878 0.         0.09211442 0.\n",
      "  0.         0.314151   0.8121104  0.         0.5349524  0.73000014\n",
      "  0.         0.         0.         0.4383371  0.         0.6461518\n",
      "  0.06840402 0.13271318 0.42011806 0.         0.14866412 0.45915344\n",
      "  0.         0.         0.11904608 0.67657095 2.3576026  0.05960916\n",
      "  0.37451148 1.4012756  0.         0.61700296 0.         0.\n",
      "  0.         0.         0.14999902 0.         0.         0.29394466\n",
      "  0.         0.         0.         1.0715884  0.         0.\n",
      "  0.         0.30483097]]\n",
      "\n",
      "Final Output from Layer 2:\n",
      "[[0.02873782 0.04039312 0.08297987 0.04233496 0.04628451 0.0910559\n",
      "  0.05405142 0.03008143 0.01676836 0.0731731  0.02388647 0.01823472\n",
      "  0.05444761 0.02779255 0.09108072 0.03778155 0.02241213 0.0653901\n",
      "  0.12386347 0.02925025]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the two separate models\n",
    "layer_1_interpreter = tf.lite.Interpreter(model_path=\"layer_1.tflite\")\n",
    "layer_2_interpreter = tf.lite.Interpreter(model_path=\"layer_2.tflite\")\n",
    "\n",
    "# Step 2: Allocate tensors for each model\n",
    "layer_1_interpreter.allocate_tensors()\n",
    "layer_2_interpreter.allocate_tensors()\n",
    "\n",
    "# Step 3: Define a fixed input for testing the models (shape: [1, 40])\n",
    "fixed_input = np.array([[1.0] * 40], dtype=np.float32)\n",
    "\n",
    "# Step 4: Set up the input and output for Layer 1\n",
    "input_details_1 = layer_1_interpreter.get_input_details()\n",
    "output_details_1 = layer_1_interpreter.get_output_details()\n",
    "\n",
    "# Set the input tensor for Layer 1\n",
    "layer_1_interpreter.set_tensor(input_details_1[0]['index'], fixed_input)\n",
    "\n",
    "# Step 5: Run inference for Layer 1\n",
    "layer_1_interpreter.invoke()\n",
    "\n",
    "# Retrieve the output from Layer 1\n",
    "intermediate_output = layer_1_interpreter.get_tensor(output_details_1[0]['index'])\n",
    "\n",
    "# Step 6: Set up the input and output for Layer 2\n",
    "input_details_2 = layer_2_interpreter.get_input_details()\n",
    "output_details_2 = layer_2_interpreter.get_output_details()\n",
    "\n",
    "# Set the output of Layer 1 as input for Layer 2\n",
    "layer_2_interpreter.set_tensor(input_details_2[0]['index'], intermediate_output)\n",
    "\n",
    "# Step 7: Run inference for Layer 2\n",
    "layer_2_interpreter.invoke()\n",
    "\n",
    "# Retrieve the final output from Layer 2\n",
    "final_output = layer_2_interpreter.get_tensor(output_details_2[0]['index'])\n",
    "\n",
    "# Step 8: Print the results for verification\n",
    "print(\"Fixed Input to Layer 1:\")\n",
    "print(fixed_input)\n",
    "print(\"\\nOutput of Layer 1 (Intermediate Output):\")\n",
    "print(intermediate_output)\n",
    "print(\"\\nFinal Output from Layer 2:\")\n",
    "print(final_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
